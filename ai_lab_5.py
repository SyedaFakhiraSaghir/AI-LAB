# -*- coding: utf-8 -*-
"""AI LAB 5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1olE2QU6IST3pEy10TcfRQquCUhgOJnQa
"""

!pip install python-chess

import chess
import heapq

# simple material-based evaluation function
def evaluate(board):
    piece_value = {
        chess.PAWN: 1,
        chess.KNIGHT: 4,
        chess.BISHOP: 3,
        chess.ROOK: 5,
        chess.QUEEN: 6
    }
    score = 0
    for piece in piece_value:
        score += len(board.pieces(piece, chess.WHITE)) * piece_value[piece]
        score -= len(board.pieces(piece, chess.BLACK)) * piece_value[piece]
    return score

# beam search function for chess
def beam_search_chess(board, beam_width=3, depth_limit=2):
    beam = [(evaluate(board), [], board)]  #evaluation score, move sequence, board
    for depth in range(depth_limit):
        candidates = []
        for score, moves, board_state in beam:
            if board_state.is_game_over():
                candidates.append((score, moves, board_state))
                continue
            for move in board_state.legal_moves:
                new_board = board_state.copy()
                new_board.push(move)
                new_score = evaluate(new_board)
                candidates.append((new_score, moves + [move], new_board))

        # keep top beam_width boards (maximize for white, minimize for black)
        if board.turn == chess.WHITE:
            beam = heapq.nlargest(beam_width, candidates, key=lambda x: x[0])
        else:
            beam = heapq.nsmallest(beam_width, candidates, key=lambda x: x[0])

    best_score, best_moves, _ = beam[0]
    return best_moves, best_score

#current board state
board = chess.Board()
beam_width = 3
depth_limit = 2

# running beam search
moves, score = beam_search_chess(board, beam_width, depth_limit)

#prinitng best move sequence and evaluation
print("Best move sequence:\n")
for m in moves:
    print(m.uci(), end=' ')
print ("\n")
board_copy = board.copy()
for m in moves:
    board_copy.push(m)
    print(board_copy)
    print("-" * 20)
print(f"\nEvaluation score: {score}")

# Design a hill climbing algorithm to find the shortest delivery route among a set of
# locations. Make incremental changes to the route and accept them only if they reduce
# the total distance.
# Input: List of coordinates for delivery points.
# Output: Optimized route and the total distance covered.
import random
import math

def distance(p1, p2):
    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

def total_distance(route):
    dist = 0
    for i in range(len(route) - 1):
        dist += distance(route[i], route[i + 1])
    return dist

def get_neighbor(route):
    new_route = route[:]
    i, j = random.sample(range(len(route)), 2)
    new_route[i], new_route[j] = new_route[j], new_route[i]
    return new_route

def hill_climbing(locations, max_iter=1000):
    current = locations[:]
    random.shuffle(current)  #random route
    current_dist = total_distance(current)

    for _ in range(max_iter):
        neighbor = get_neighbor(current)
        neighbor_dist = total_distance(neighbor)
        # accept the neighbor if it's better
        if neighbor_dist < current_dist:
            current = neighbor
            current_dist = neighbor_dist
    return current, current_dist

#list of delivery coordinates
locations = [(0, 0), (2, 3), (5, 2), (1, 6), (7, 8), (3, 4)]

best_route, best_dist = hill_climbing(locations)

# output result
print("optimized delivery route:")
for point in best_route:
    print(point)
print(f"Total distance: {best_dist}")

# Implement a genetic algorithm to solve the TSP (Traveling Salesman Problem) for a
# given set of 10 cities.
import random
import math

def distance(p1, p2):
    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

def total_distance(route):
    dist = 0
    for i in range(len(route)):
        dist += distance(route[i], route[(i + 1) % len(route)])
    return dist

# make a bunch of random routes to start with
def init_population(cities, size):
    return [random.sample(cities, len(cities)) for _ in range(size)]

def selection(pop, retain=0.2):
    graded = sorted(pop, key=total_distance)
    keep = int(len(graded) * retain)
    return graded[:keep]

def crossover(parent1, parent2):
    start, end = sorted(random.sample(range(len(parent1)), 2))
    child = parent1[start:end]
    for city in parent2:
        if city not in child:
            child.append(city)
    return child

def mutate(route, rate=0.1):
    if random.random() < rate:
        i, j = random.sample(range(len(route)), 2)
        route[i], route[j] = route[j], route[i]
    return route

def genetic_algorithm(cities, pop_size=100, generations=500):
    population = init_population(cities, pop_size)
    for _ in range(generations):
        selected = selection(population)
        children = []
        while len(children) < pop_size:
            p1, p2 = random.sample(selected, 2)
            child = crossover(p1, p2)
            child = mutate(child)
            children.append(child)
        population = children
    best_route = min(population, key=total_distance)
    return best_route, total_distance(best_route)

#10 random city coordinates
cities = [(random.randint(0, 100), random.randint(0, 100)) for _ in range(10)]

# run the algorithm
best, cost = genetic_algorithm(cities)

# printing out the best route
print("best route found:")
for city in best:
    print(city)
print(f"total distance: {cost:.2f}")